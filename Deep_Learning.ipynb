{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaramesh-ds/datascience/blob/master/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUFrLW1j-HVo",
        "colab_type": "text"
      },
      "source": [
        "# **Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTXOGdaz4wy0"
      },
      "source": [
        "# Richer syntax highlighting\n",
        "\n",
        "Improved support for nested languages:\n",
        "\n",
        "```notebook-python\n",
        "df = pd.io.gbq.read_gbq('''\n",
        "  SELECT \n",
        "    REGEXP_EXTRACT(name, '[a-zA-Z]+'),\n",
        "    SUM(number) as count\n",
        "  FROM `bigquery-public-data.usa_names.usa_1910_2013`\n",
        "  WHERE state = 'TX'\n",
        "  GROUP BY name\n",
        "  ORDER BY count DESC\n",
        "  LIMIT 100\n",
        "''')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XGWbrJb-LqO",
        "colab_type": "text"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCDYIyBH-Rkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "5e10e0ea-2703-47f7-aab0-b75a4bb232af"
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veS_I2lg-SCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48f8a679-5590-4b34-ce37-d07b06c5b63e"
      },
      "source": [
        "# Set the number of features we want\n",
        "number_of_features = 1000\n",
        "\n",
        "# Load data and target vector from movie review data\n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
        "\n",
        "# Convert movie review data to a one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
        "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NK9Entt-UXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a449b16-18c6-471e-e4eb-192861c2d413"
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add a dropout layer for input layer\n",
        "network.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Add a dropout layer for previous hidden layer\n",
        "network.add(layers.Dropout(0.5))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Add a dropout layer for previous hidden layer\n",
        "network.add(layers.Dropout(0.5))\n",
        "\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yUxCFPt-WuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "078499c8-e383-4091-cd0b-00061ca3d63c"
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dutWS9Fu-kuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "dc2fe143-fa94-463a-a870-e2da8121651d"
      },
      "source": [
        "# Train neural network\n",
        "history = network.fit(train_features, # Features\n",
        "                      train_target, # Target vector\n",
        "                      epochs=3, # Number of epochs\n",
        "                      verbose=0, # No output\n",
        "                      batch_size=100, # Number of observations per batch\n",
        "                      validation_data=(test_features, test_target)) # Data for evaluation"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXCfQirw-mo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K \n",
        "\n",
        "# Set that the color channel value will be first\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "# Set seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2573y0N-pn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edbce14c-61a7-48fa-c2fe-bb2d0d4033e2"
      },
      "source": [
        "# Set image information\n",
        "channels = 1\n",
        "height = 28\n",
        "width = 28\n",
        "\n",
        "# Load data and target from MNIST data\n",
        "(train_data, train_target), (test_data, test_target) = mnist.load_data()\n",
        "\n",
        "# Reshape training image data into features\n",
        "train_data = train_data.reshape(train_data.shape[0], channels, height, width)\n",
        "\n",
        "# Reshape test image data into features\n",
        "test_data = test_data.reshape(test_data.shape[0], channels, height, width)\n",
        "\n",
        "# Rescale pixel intensity to between 0 and 1\n",
        "train_features = train_data / 255\n",
        "test_features = test_data / 255\n",
        "\n",
        "# One-hot encode target\n",
        "train_target = np_utils.to_categorical(train_target)\n",
        "test_target = np_utils.to_categorical(test_target)\n",
        "number_of_classes = test_target.shape[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwxn2pJ6-rlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c4cec96-40e7-4ee0-f6e0-d9e1ca378a3c"
      },
      "source": [
        "# Start neural network\n",
        "network = Sequential()\n",
        "\n",
        "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
        "network.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(channels, width, height), activation='relu'))\n",
        "\n",
        "# Add max pooling layer with a 2x2 window\n",
        "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add dropout layer\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "# Add layer to flatten input\n",
        "network.add(Flatten())\n",
        "\n",
        "# # Add fully connected layer of 128 units with a ReLU activation function\n",
        "network.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add dropout layer\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "# Add fully connected layer with a softmax activation function\n",
        "network.add(Dense(number_of_classes, activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yuP-bwt-t1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='categorical_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H56vXlnR-vxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22668e28-d224-42a7-d9a6-617c5595d1d8"
      },
      "source": [
        "# Train neural network\n",
        "network.fit(train_features, # Features\n",
        "            train_target, # Target\n",
        "            epochs=2, # Number of epochs\n",
        "            verbose=0, # Don't print description after each epoch\n",
        "            batch_size=1000, # Number of observations per batch\n",
        "            validation_data=(test_features, test_target)) # Data for evaluation"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba6e892f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KOW8DRq-xTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f9FXr7I-z6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the number of features we want\n",
        "number_of_features = 1000\n",
        "\n",
        "# Load data and target vector from movie review data\n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
        "\n",
        "# Convert movie review data to one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
        "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4Z6Xo5J-1z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJr7zb5h-4Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLibInbdAEc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b817e02-c568-42b3-f75c-0a330a5162d8"
      },
      "source": [
        "# Train neural network\n",
        "network.fit(train_features, # Features\n",
        "            train_target, # Target\n",
        "            epochs=2, # Number of epochs\n",
        "            verbose=0, # Don't print description after each epoch\n",
        "            batch_size=1000, # Number of observations per batch\n",
        "            validation_data=(test_features, test_target)) # Data for evaluation"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba64b50438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab9CwXONAH2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRzH5SuJAML-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the number of features we want\n",
        "number_of_features = 1000\n",
        "\n",
        "# Load data and target vector from movie review data\n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
        "\n",
        "# Convert movie review data to one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
        "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lvLFt4TAOAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjWDLARYAQ0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UmlY9H7ATJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fc8823b5-5b88-4697-fb40-1c3c2002df5e"
      },
      "source": [
        "# Train neural network\n",
        "history = network.fit(train_features, # Features\n",
        "                      train_target, # Target vector\n",
        "                      epochs=3, # Number of epochs\n",
        "                      verbose=1, # Print description after each epoch\n",
        "                      batch_size=100, # Number of observations per batch\n",
        "                      validation_data=(test_features, test_target)) # Data for evaluation"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 2s 62us/step - loss: 0.4198 - acc: 0.8116 - val_loss: 0.3406 - val_acc: 0.8526\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 1s 43us/step - loss: 0.3232 - acc: 0.8640 - val_loss: 0.3270 - val_acc: 0.8606\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 1s 45us/step - loss: 0.3122 - acc: 0.8680 - val_loss: 0.3385 - val_acc: 0.8546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580t7F72AWBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGREIz7AZHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the number of features we want\n",
        "number_of_features = 1000\n",
        "\n",
        "# Load data and target vector from movie review data\n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
        "\n",
        "# Convert movie review data to one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
        "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKD6yovRBFPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzngbpW5BHMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCEyC8ulBIyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b878a884-fd76-4e3e-fc31-15ce22844910"
      },
      "source": [
        "# Train neural network\n",
        "history = network.fit(train_features, # Features\n",
        "                      train_target, # Target vector\n",
        "                      epochs=3, # Number of epochs\n",
        "                      verbose=1, # Print description after each epoch\n",
        "                      batch_size=100, # Number of observations per batch\n",
        "                      validation_data=(test_features, test_target)) # Data for evaluation"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 2s 63us/step - loss: 0.4198 - acc: 0.8117 - val_loss: 0.3396 - val_acc: 0.8536\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 1s 43us/step - loss: 0.3231 - acc: 0.8641 - val_loss: 0.3280 - val_acc: 0.8603\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 1s 43us/step - loss: 0.3120 - acc: 0.8677 - val_loss: 0.3381 - val_acc: 0.8543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooAtWVB-BK25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import reuters\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpeSnk6aBRKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b795f493-d004-46fc-881c-9457297b145b"
      },
      "source": [
        "# Set the number of features we want\n",
        "number_of_features = 5000\n",
        "\n",
        "# Load feature and target data\n",
        "(train_data, train_target_vector), (test_data, test_target_vector) = reuters.load_data(num_words=number_of_features)\n",
        "\n",
        "# Convert feature data to a one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
        "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\n",
        "\n",
        "# One-hot encode target vector to create a target matrix\n",
        "train_target = to_categorical(train_target_vector)\n",
        "test_target = to_categorical(test_target_vector)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ-e4asOBUIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=100, activation='relu', input_shape=(number_of_features,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=100, activation='relu'))\n",
        "\n",
        "# Add fully connected layer with a softmax activation function\n",
        "network.add(layers.Dense(units=46, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCmNBwVcBWhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='categorical_crossentropy', # Cross-entropy\n",
        "                optimizer='rmsprop', # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjQdhoN2BYSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train neural network\n",
        "history = network.fit(train_features, # Features\n",
        "                      train_target, # Target vector\n",
        "                      epochs=3, # Three epochs\n",
        "                      verbose=0, # No output\n",
        "                      batch_size=100, # Number of observations per batch\n",
        "                      validation_data=(test_features, test_target)) # Data to use for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4LugrUbBaFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIhMvW1-BcBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}